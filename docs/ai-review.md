# Step 1: project setup

The project setup is completed. the files were generated by the prompt, and it followed the structure and rules defined in the prompt.

There are some issues that need to be addressed:

1. improve the fixture to use a js file instead of a json file to store the test data.
2. standarize naming conventions early on to avoid confusion.
3. Add a lightweight barrel export for pages and flows.
4. we needed to improve the playwright configuration
   a. add use.screenshot configuration
   b. add use.video configuration
   c. use html reporter
5. move the base url to playwright.config.js
6. add Prettier for consistent code style

# Step 2: app exploration

The app exploration is completed. the flows were identified and documented in the e2e-test-flows.md file.

The IA could have been more thorough in identifying all the possible flows and their risk levels. but I made some changes into the risk classification to make it more accurate.

I change the risk classification in the flows Cart Operations and Product Management from Medium to High. this because these flows are critical to the application and should be tested more frequently.

and the other flows do not test complete flows, they are just testing single actions. and the ability to move through all the products and the posibility to change the quantity of products in the cart is important to test.

# step 3: test implementation (Complete Checkout Flow)

the test implementation is completed. the test is passing and the report is generated.

The IA generated the test code but it was not following the structure and rules defined in the prompt, It was capable to identify the flows and create the test code following the structure and rules defined in the prompt, but all the flow was generated in one file, I had to split the logic into several flow files to make it more maintainable.

Also the locator weren't accurate and I had to fix it to follow the best practices.

It algo use the function goto to move between pages, but it should click on the link or button to move between pages. it was fixed

# step4 test implementation (Product Managment)

the test implementation is completed. the test is passing and the report is generated.

The IA kept making the same mistakes as in the previous step, it was not following the structure and rules defined in the prompt, and it was not splitting the logic into several flow files to make it more maintainable, I need improve those chnages and I need to make the prompt more clear to avoid this.

The IA also made up a test that was failing due to the feature is not working as expected, but the test was correct, it should be a suggestion to improve the feature.

# step5 test implementation (Cart Operations)

test implementation is completed. the test is passing and the report is generated.

The IA kept making some mistakes like use pages into the specs files, it should use the flow files to move between pages. there are also some locators that were not accurate and I had to fix it to follow the best practices.

The output was better including more details into the prompt, I need to avoid the IA to infer the structure and rules defined in the prompt, I need to be more specific and clear in the prompt.


# Final thoughts

The IA is a powerful tool but it needs to be used with caution. I need to be more specific and clear in the prompt to avoid the IA to infer the structure and rules defined in the prompt. I also need to be more specific and clear in the prompt to avoid the IA to make up tests that are not related to the application.

## what went well
The IA created a good structure, I need to make some improvements to make it more maintainable and to follow the best practices, but it was a good start.
It was able to analyze the application and suggested good test cases the priority of the test cases was not clear, but I was able to improve it, maybe it need more information about the business rules and the application flow.
## what needs improvement
The IA needs kept making the same mistakes no matter how many times I try to improve the prompt, it needs to be more specific and clear in the prompt to avoid the IA to infer the structure and rules defined in the prompt.

The IA made up some test cases that were not related to the application flows
At the beginning the IA used wrong locators but it was able to improve in the next steps


## What Should Not Be Delegated to AI

AI should not be responsible for defining test strategy,
risk prioritization, critical flow selection or final
architectural decisions.

While AI can assist in generating initial code and
suggesting test scenarios, human judgment is required
to review, refactor and validate the relevance and
stability of the solution.

Critical thinking, business understanding and risk-based
testing remain exclusively to the tester.

## Which human decisions improved the framework

1. I improved the structure of the code to make it more maintainable and to follow the best practices.
2. I improved the locators to make them more accurate and to follow the best practices.
3. I improved the test cases to make them more relevant and to follow the best practices.
4. I improved the prompt to make it more specific and clear to avoid the IA to infer the structure and rules defined in the prompt.
5. There were some test cases that do not have good validations, I added them

## Current Limitations of Playwright MCP

1. MCP does not understand real business context or priorities.
2. It generates technically correct but often superficial code.
3. It depends on prompt quality; insufficient prompts lead to poor test outputs.
4. It does not detect design anti-patterns or ensure long-term code maintainability.
5. It cannot guarantee that generated tests are meaningful or provide real quality coverage.
6. It cannot decide what should be tested versus what should be postponed based on risk.

These limitations were addressed through human code review,
manual refactoring, and risk-based testing decisions made by the QA Engineer.

## Lessons learned

1. I need to be more specific and clear in the prompt to avoid the IA to infer the structure and rules defined in the prompt.
2. we can't trust the IA to generate good test cases, we need to review and validate them.
3. we can't trust the IA to generate good locators, we need to review and validate them.
4. we can't trust the IA to generate good code, we need to review and validate it.
5. 


